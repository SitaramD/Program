{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920efa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk Forward  04122022 Scott Sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fe0b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'backtest' has no attribute 'backtest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 157>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m     backtest\u001b[38;5;241m.\u001b[39mbacktest(test_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m, output_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_1year.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[43mrun_walk_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mrun_walk_forward\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m test_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    154\u001b[0m test_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_test_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 155\u001b[0m \u001b[43mbacktest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbacktest\u001b[49m(test_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m, output_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_1year.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'backtest' has no attribute 'backtest'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import backtest\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    # candle sign is calculated using closing and opening prices if close is greater than open sign is +1 else sign is -1\n",
    "    df['candle_sign'] = np.sign(df['Close'] - df['Open'])\n",
    "\n",
    "    # calculate rolling average of last x candlesizes and signs and shift by 1\n",
    "    df['daily_returns'] = df['Close'].pct_change()\n",
    "\n",
    "    # if open = close it is assigned +1\n",
    "    df.loc[df['candle_sign'] == 0, 'candle_sign'] = 1\n",
    "\n",
    "    # using the formula calculate the candle size\n",
    "    df['candle_size'] = np.sign(df['Close'] - df['Open']) * (\n",
    "            df['High'] - df['Low']) * 100 / df['Low']\n",
    "\n",
    "    # rolling means of last 7 values (including the current one)\n",
    "    df['rolling_candle_size'] = df['candle_size'].rolling(7).mean()\n",
    "    df['rolling_candle_sign'] = df['candle_sign'].rolling(7).mean()\n",
    "    df['rolling_returns'] = df['daily_returns'].rolling(7).mean()\n",
    "\n",
    "    # rolling std of last 7 values (including the current one)\n",
    "    df['rolling_candle_size_std'] = df['candle_size'].rolling(7).std()\n",
    "    df['rolling_returns_std'] = df['daily_returns'].rolling(7).std()\n",
    "    df['rolling_std_dev'] = df['candle_size'].rolling(7).std()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def walk_forward_sets(end_year, train_duration=5, test_duration=1):\n",
    "    st = time.time()\n",
    "    path_to_data_folder = \"data\"\n",
    "    signal_file_path = os.path.join(path_to_data_folder, \"D:\\\\A Scott Internship\\\\Programs\\\\Walkforward 04122022\\\\Signals for SPY 2000 to 102822.xlsx\")\n",
    "    data_file_path = os.path.join(path_to_data_folder, \"D:\\\\A Scott Internship\\\\Programs\\\\Walkforward 04122022\\\\ETF Ticker Data thru 102822.xlsx\")\n",
    "\n",
    "    df_signal = pd.read_excel(signal_file_path, sheet_name=\"Signals\")\n",
    "    df_signal['Date/Time'] = pd.to_datetime(df_signal['Date/Time'])\n",
    "\n",
    "    #df_value = pd.read_excel(signal_file_path, sheet_name=\"Values\")\n",
    "    #df_value['Date/Time'] = pd.to_datetime(df_value['Date/Time'])\n",
    "\n",
    "    df_data = pd.read_excel(data_file_path)\n",
    "    df_data_spy = df_data.loc[df_data['Ticker'] == \"SPY\"].reset_index(drop=True)\n",
    "\n",
    "    df_data_spy['Date/Time'] = pd.to_datetime(df_data_spy['Date/Time'])\n",
    "    df_data_spy.sort_values(by='Date/Time', ascending=True, inplace=True)\n",
    "\n",
    "    # split data into train and test\n",
    "    # divide the data into train and test sets\n",
    "    df_data_spy = add_features(df_data_spy)\n",
    "    df_data_spy = pd.merge(df_data_spy, df_signal, on='Date/Time', how='left')\n",
    "    #df_data_spy = pd.merge(df_data_spy, df_value, on='Date/Time', how='left')\n",
    "\n",
    "    df_data_spy.dropna(inplace=True)\n",
    "    df_data_spy = df_data_spy.reset_index(drop=True)\n",
    "\n",
    "    # train_size = int(df_data_spy.shape[0] * 0.8)\n",
    "\n",
    "    xtrain = df_data_spy.loc[(df_data_spy['Date/Time'] > datetime.datetime(year=end_year - train_duration, month=1, day=1)) & (\n",
    "            df_data_spy['Date/Time'] < datetime.datetime(year=end_year, month=1, day=1)), :].reset_index(drop=True)\n",
    "    xtest = df_data_spy.loc[(df_data_spy['Date/Time'] >= datetime.datetime(year=end_year, month=1, day=1)) &\n",
    "                            (df_data_spy['Date/Time'] <= datetime.datetime(year=end_year+test_duration, month=1,\n",
    "                                                                           day=1)), :].reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    xtrain['target'] = 10\n",
    "    xtrain.loc[xtrain['daily_returns'] > xtrain['daily_returns'].quantile(0.75), 'target'] = 1\n",
    "    xtrain.loc[xtrain['daily_returns'] < xtrain['daily_returns'].quantile(0.25), 'target'] = -1\n",
    "    xtrain['target'] = xtrain['target'].shift(-2)\n",
    "    return xtrain, xtest\n",
    "\n",
    "def walkforward_train(xtrain):\n",
    "    xtrain.drop(['Date/Time', 'Open', 'Close', 'High', 'Low', 'Ticker'], axis=1, inplace=True)\n",
    "\n",
    "    # drop rows with missing values\n",
    "    xtrain.dropna(inplace=True)\n",
    "    xtrain.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ytrain = xtrain['target']\n",
    "    xtrain = xtrain.loc[:, xtrain.columns != 'target']\n",
    "\n",
    "    # for machine learning algo hyperparameter tuning 3 fold custom cv is used\n",
    "    params = {\n",
    "        'max_depth': [5, 6, 7, -1],\n",
    "        'num_leaves': [12, 24, 32],\n",
    "        'n_estimators': [100, 200],\n",
    "        'colsample_bytree': [0.5, 0.7, 0.8, 0.9],\n",
    "        'subsample': [0.5, 0.7, 0.8, 0.9]\n",
    "    }\n",
    "\n",
    "\n",
    "    model = lgb.LGBMClassifier(random_state=121, class_weight='balanced')\n",
    "\n",
    "    # since its time series data we define custom cv splits\n",
    "    train_1, test_1 = xtrain.loc[:int(0.8 * xtrain.shape[0])].index, xtrain.loc[int(0.8 * xtrain.shape[0]):].index\n",
    "    train_2, test_2 = xtrain.loc[:int(0.85 * xtrain.shape[0])].index, xtrain.loc[int(0.85 * xtrain.shape[0]):].index\n",
    "    train_3, test_3 = xtrain.loc[:int(0.9 * xtrain.shape[0])].index, xtrain.loc[int(0.9 * xtrain.shape[0]):].index\n",
    "    cv = [(train_1, test_1), (train_2, test_2), (train_3, test_3)]\n",
    "\n",
    "    clf = GridSearchCV(model, params, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "\n",
    "    clf.fit(xtrain.values, ytrain)\n",
    "\n",
    "    model = clf.best_estimator_\n",
    "\n",
    "    rfe = RFECV(model, step=1, cv=cv)\n",
    "    rfe.fit(xtrain.values, ytrain)\n",
    "    features = xtrain.loc[:, rfe.support_].columns.values\n",
    "    joblib.dump(features, 'features.pkl')\n",
    "\n",
    "    # fit model on complete training data\n",
    "    model.fit(xtrain[features].values, ytrain)\n",
    "\n",
    "    # save the model\n",
    "    joblib.dump(model, 'model_lgb.pkl')\n",
    "\n",
    "def walkforward_test(test, year):\n",
    "    features = joblib.load('features.pkl')\n",
    "\n",
    "    model = joblib.load('model_lgb.pkl')\n",
    "\n",
    "    test['Date/Time'] = pd.to_datetime(test['Date/Time'])\n",
    "    test.dropna(inplace=True)\n",
    "\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    test[\"pred\"] = model.predict(test[features])\n",
    "\n",
    "    # Results on test set\n",
    "    # backtest.backtest(test, 'pred', output_filename=\"output_1year_{}.html\".format(year))\n",
    "    return test\n",
    "\n",
    "\n",
    "def run_walk_forward():\n",
    "    test_df = pd.DataFrame()\n",
    "    for year in range(2016, 2022, 1):\n",
    "        print(year)\n",
    "        train, test = walk_forward_sets(year)\n",
    "        walkforward_train(train)\n",
    "        test = walkforward_test(test, year)\n",
    "        test_df = pd.concat([test, test_df], axis=0)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.to_csv(\"check_test_data.csv\", index=False)\n",
    "    backtest.backtest(test_df, 'pred', output_filename=\"output_1year.html\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_walk_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec728f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
